# -*- coding: utf-8 -*-
"""CustomDLBinaryClassificationDDI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dEcmOO_r4KjC-m8BrgOU_O6_zB-zJZEp
"""

!pip install tensorflow scikit-learn pandas numpy rdkit

# --- Install Dependencies ---
# !pip install tensorflow scikit-learn pandas numpy rdkit

import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
from rdkit import Chem, RDLogger
from rdkit.Chem import AllChem, MACCSkeys
from rdkit.DataStructs import ConvertToNumpyArray, TanimotoSimilarity
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Disable RDKit warnings
RDLogger.DisableLog('rdApp.*')

# Load and clean data
def load_data(xlsx_path):
    df = pd.read_excel(xlsx_path, usecols=['Drug1', 'Drug2', 'Y'], dtype=str)
    df = df.dropna().reset_index(drop=True)
    df = df[df['Drug1'].apply(lambda x: Chem.MolFromSmiles(x) is not None)]
    df = df[df['Drug2'].apply(lambda x: Chem.MolFromSmiles(x) is not None)]
    df['Y'] = df['Y'].astype(int)
    return df


# Generate fingerprints
def generate_fingerprints(smiles, radius=2, nBits=1024):
    mol = Chem.MolFromSmiles(smiles)
    morgan = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits)
    maccs = MACCSkeys.GenMACCSKeys(mol)
    fp = np.zeros((nBits + 167,), dtype=np.float32)
    ConvertToNumpyArray(morgan, fp[:nBits])
    ConvertToNumpyArray(maccs, fp[nBits:])
    return fp

# Prepare features and labels
def prepare_dataset(df, sim_threshold=0.3, total_limit=190000):
    pos_limit = total_limit // 2

    unique_smiles = list(set(df['Drug1']).union(set(df['Drug2'])))
    fingerprints = {smi: generate_fingerprints(smi) for smi in unique_smiles}

    all_positives = df[df['Y'] == 1][['Drug1', 'Drug2']].values.tolist()
    if len(all_positives) > pos_limit:
        positives = random.sample(all_positives, pos_limit)
    else:
        positives = all_positives
        pos_limit = len(positives)  # update if less available

    # Sample negatives
    neg_samples = []
    while len(neg_samples) < pos_limit:
        d1, d2 = random.sample(unique_smiles, 2)
        if [d1, d2] in positives or [d2, d1] in positives:
            continue
        sim = TanimotoSimilarity(Chem.RDKFingerprint(Chem.MolFromSmiles(d1)),
                                 Chem.RDKFingerprint(Chem.MolFromSmiles(d2)))
        if sim < sim_threshold:
            neg_samples.append([d1, d2])

    data = positives + neg_samples
    labels = [1] * len(positives) + [0] * len(neg_samples)

    X1 = np.array([fingerprints[d1] for d1, d2 in data])
    X2 = np.array([fingerprints[d2] for d1, d2 in data])
    y = np.array(labels)

    return X1, X2, y



# Build model
def build_model(input_dim):
    inp1 = Input(shape=(input_dim,), name='drug1_fp')
    inp2 = Input(shape=(input_dim,), name='drug2_fp')

    def subnet(x):
        x = Dense(256, activation='relu')(x)
        x = BatchNormalization()(x)
        x = Dropout(0.3)(x)
        x = Dense(128, activation='relu')(x)
        x = BatchNormalization()(x)
        return x

    x1 = subnet(inp1)
    x2 = subnet(inp2)
    x = Concatenate()([x1, x2])
    x = Dense(64, activation='relu')(x)
    x = Dropout(0.3)(x)
    out = Dense(1, activation='sigmoid')(x)

    model = Model(inputs=[inp1, inp2], outputs=out)
    model.compile(optimizer=Adam(1e-3),
                  loss='binary_crossentropy',
                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])
    return model

# Main execution
xlsx_path = "drugbank_ddi_dataset.xlsx"  # replace with your actual file path
df = load_data(xlsx_path)

X1, X2, y = prepare_dataset(df, sim_threshold=0.3, total_limit=190000)

X1_train, X1_val, X2_train, X2_val, y_train, y_val = train_test_split(X1, X2, y, test_size=0.2, random_state=42)

model = build_model(X1.shape[1])
callbacks = [
    EarlyStopping(patience=5, restore_best_weights=True),
    ModelCheckpoint("hybrid_ddi_model_final.h5", save_best_only=True)
]

history = model.fit([X1_train, X2_train], y_train,
                    validation_data=([X1_val, X2_val], y_val),
                    epochs=20, batch_size=128, callbacks=callbacks, verbose=1)

# Evaluation
val_preds = model.predict([X1_val, X2_val]).flatten()
val_preds_bin = (val_preds >= 0.5).astype(int)
train_preds = model.predict([X1_train, X2_train]).flatten()
train_preds_bin = (train_preds >= 0.5).astype(int)

print("\nTrain Report:")
print(classification_report(y_train, train_preds_bin))

print("\nValidation Report:")
print(classification_report(y_val, val_preds_bin))

import matplotlib.pyplot as plt

def plot_history(history):
    available_metrics = history.history.keys()
    metric_base_names = ['loss', 'accuracy', 'precision', 'recall']

    plt.figure(figsize=(16, 10))
    subplot_index = 1

    for base in metric_base_names:
        # Find actual metric key (e.g., 'precision' or 'precision_1')
        train_key = next((k for k in available_metrics if k.startswith(base) and not k.startswith('val_')), None)
        val_key = next((k for k in available_metrics if k.startswith(f'val_{base}')), None)

        if train_key and val_key:
            plt.subplot(2, 2, subplot_index)
            plt.plot(history.history[train_key], label='Train')
            plt.plot(history.history[val_key], label='Validation')
            plt.title(base.capitalize())
            plt.xlabel('Epochs')
            plt.ylabel(base.capitalize())
            plt.legend()
            plt.grid(True)
            subplot_index += 1

    plt.tight_layout()
    plt.show()


plot_history(history)

from google.colab import files
files.download("hybrid_ddi_model_final.h5")